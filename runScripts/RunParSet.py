#Run Parameter Sets
# Gets parameters from parameter file generated by SC_GenerateParamSet.py

import pandas as pd
import numpy as np
import random
import sys
import os
import math
#import ReadPFB as pfb
import pfio #Hoang's Parflow Read/Write Module
import time
import datetime

from ProcessRun import *

############# Functions ##############
# pfidbGen: pfidb generator
# createRunDir: creates parflow run directory for individual run
# getInputRow: get single set of run parameters
# processData: run post processing

# two different overall run behaviors
    # runSet runs a single simulation, in it's own folder
    # runSingleFolder, runs a series of simulations, in sequence, in the same folder.

def pfidbGen(runData):              # generates PFIDB File for Run given input data set
    '''creates pfidb file for parflow run'''

    # modify input data set
    runData = runData.drop(labels='n') # remove this values, not needed
    runData = runData.astype(str)

    # evaluate key and value lengths - these variables are needed for the pfidb file
    keyLengths=[len(i) for i in runData.keys()]
    valueLengths=[len(i) for i in np.array(runData)]

    # open the output file, then first save the number of keys
    outfn = 'test.pfidb'
    f = open(outfn,'a')
    f.write(str(len(runData.keys())))

    # loop through all the keys, add the key len, key, value len, and value to the pfidb file
    keyVals = np.array(runData)
    for i in range(len(keyVals)):
        f.write("\n")
        f.write(str(keyLengths[i]))
        f.write("\n")
        f.write(runData.keys()[i])
        f.write("\n")
        if keyVals[i] == 'nan': #nan values should be empty strings
            f.write("0")
            f.write("\n")
            #f.write("\n")
        else:
            f.write(str(valueLengths[i]))
            f.write("\n")
            f.write(keyVals[i])
    f.close()

def createPumpFile(pumpVRate, pumpDepth_min, pumpDepth_max, dz, nz):
    '''creates parflow pumping file, given pumping rate (m3/hr), pumping depth range, and DZ/NZ'''

    # create pumping vector: for single column this is a simple vector the length of NZ
    pumpData = np.zeros(nz)

    # determine which layers will have pumping
    layTop = np.array([i for i in range(dz*(nz-1),-dz,-dz)])
    layBottom = layTop + dz
    layMiddle = (layTop + layBottom)/2.0
    pumpLayers = (layMiddle < pumpDepth_max) & (layMiddle > pumpDepth_min)
    pumpData[pumpLayers] = 1 # select these as the pumping layers, set to 1 for easy multiplication later

    # evalute pumping rate
    nlayers = pumpData.sum()
    pumpDepth = nlayers*dz
    assert pumpDepth == (pumpDepth_max - pumpDepth_min) #sanity check
    pumpRate = pumpVRate/1.12/1.12/pumpDepth # number of layers does not matter here, only the total depth, because the rate is 1/hr 
    pumpData = pumpData * pumpRate

    # save the file
    outfn = 'test_pump.txt'
    #pfio.pfwrite(pumpData, outfn, 0 , 0 , 0, 1, 1, nz)
    # pfio doesn't seem to like single column? or I"m doing it wrong... very possible
    with open(outfn,"w") as f:
        f.write('1 1 ')
        f.write(str(nz))
        for i in range(nz):
            f.write('\n')
            f.write(str(pumpData[i]))
    # convert text to pfb
    os.system('tclsh /glade/scratch/lmthatch/SCTests/runScripts/ConvertPFB2TXT 0 test_pump.txt test_pump.pfb')

def createRunDir(n): #(clmDir,currTestDir) input parameters ignored for now, assuming we're in the current directory and the clm directory has been copied into this folder
    '''create run directory for parflow files'''

    # create run directory
    runDir = 'test' + str(n)
    os.system('mkdir ' + runDir)

    # copy over clm driver files
    os.system("cp ../clm_input/drv_clmin.dat " + runDir)
    os.system("cp ../clm_input/drv_vegm.dat " + runDir)
    os.system("cp ../clm_input/drv_vegp.dat " + runDir)
    return runDir

def getInputRow(n,paramFile): # gets the input rows needed.
    '''get single parameter set from parameter file'''
    allPar = pd.read_csv(paramFile, delimiter=",", header=0) # room for improvement here, may be removed when 'well' parallelized to loop through parameter set
    linePar = allPar.iloc[n]
    return linePar

def getAllInputRows(paramFile): # gets all input rows
    '''get all parameter data sets'''
    allPar = pd.read_csv(paramFile, delimiter=",", header=0) # room for improvement here, may be removed when 'well' parallelized to loop through parameter set
    #linePar = allPar.iloc[n]
    return allPar

def runSet(parLine, parameterFN):
    #parameterFN = "ParameterSets_AutoGenPY.csv"
    # create your run directory
    newRunDir = createRunDir(parLine)

    # get your run data
    runParameters = getInputRow(parLine, parameterFN)
    #runParameters['TimingInfo.StopTime'] = 500 
    # navigate to this new folder your created
    os.chdir(newRunDir)

    # create your pfidb file
    pfidbGen(runParameters)

    # run your program
    os.system("$PARFLOW_DIR/bin/parflow test > parflow.test.log")

    # process the data
    #nclm = runParameters['Solver.CLM.RootZoneNZ']
    #totalLayers = runParameters['ComputationalGrid.NZ']
    #testn = runParameters['n']
    #runLen = runParameters['TimingInfo.StopTime']
    processDataSC(runParameters)

    os.system('rm test.pfidb')

    # delete your folder
    #os.chdir('../')
    #os.system('rm ' + newRunDir)

    return 'parameter set complete: ' + str(parLine)

def runSingleFolder(runset): # this is for running in parallel w/ a set number of maximum folders running at a time.
    # first we'll create a single run folder

    runset = runset - 1 # the GNU parallel is running a sequence from 1-5 but python wants 0-4, correct here.
    print('Running Folder ' + str(runset))
    newRunDir = createRunDir(runset)

    parameterFN = "ParameterSets_AutoGenPY_" + str(runset) + ".csv"

    # get all run parameters
    allPar = getAllInputRows(parameterFN)
    nsets = len(allPar.index)

    os.chdir(newRunDir)

    outfn = '../runTimes_' + str(runset) + '.csv'

    for currset in range(nsets):
        print('Running Set ' + str(currset))

        # get current parameter set
        runParameters = allPar.iloc[currset]

        # create your pfidb file
        pfidbGen(runParameters)
        #print('PfidbGenerated')

        # run your program
        #os.system("$PARFLOW_DIR/bin/parflow test > parflow.test.log")
        try: 
            start = time.time()
            os.system("$PARFLOW_DIR/bin/parflow test  > parflow.test.log")
            end = time.time()

            # save runtime
            totaltime = end - start
            f = open(outfn,'a')
            testn = runParameters['n']
            f.write(str(testn) + "," + str(totaltime))
            f.write("\n")
            f.close()

        #print('Parflow Run Done')

            # process the data
            #nclm = runParameters['Solver.CLM.RootZoneNZ']
            #totalLayers = runParameters['ComputationalGrid.NZ']
            #runLen = runParameters['TimingInfo.StopTime']
            processDataSC(runParameters)
            #print('Processing Complete')
            #print('Deleting old pfidb file')
        except:
            'parflow failed'
        os.system('rm test.pfidb')

    # delete the directory when all runs have been completed
    os.chdir('../')
    os.system('rm -r ' + newRunDir)

def main():
    runset = int(sys.argv[1])
    runSingleFolder(runset)

    # old def main -> When file creation not restricted (no go on Cheyenne)
    # runLine = int(sys.argv[1],"ParameterSets_AutoGenPY.csv")
    # runSet(runLine)

if __name__ == "__main__":

    main() # main is passed the line in the parameter file that you want to pull

